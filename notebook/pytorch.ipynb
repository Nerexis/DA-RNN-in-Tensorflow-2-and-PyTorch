{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dirname = Path(os.path.abspath(''))\n",
    "root = dirname.parent\n",
    "\n",
    "sys.path.insert(0, str(root))\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters & Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_DATA = True\n",
    "WINDOW_SIZE = 10\n",
    "Y_DIM = 1\n",
    "ENCODER_HIDDEN_STATES = 128\n",
    "DECODER_HIDDEN_STATES = 128\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "VALIDATION_RATIO = 0.2\n",
    "DROPOUT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NASDAQ 100 raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "raw_data =  pd.read_csv('./nasdaq100_padding.csv').values\n",
    "\n",
    "scale = StandardScaler().fit(raw_data)\n",
    "\n",
    "if NORMALIZE_DATA:\n",
    "    data = scale.transform(raw_data)\n",
    "else:\n",
    "    data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X, train_y : torch.Size([32439, 10, 82]) torch.Size([32439, 1])\n",
      "  val_X,   val_y : torch.Size([8103, 10, 82]) torch.Size([8103, 1])\n"
     ]
    }
   ],
   "source": [
    "from notebook.common import split_data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def to_tensor(array):\n",
    "    return torch.from_numpy(array).float()\n",
    "    \n",
    "\n",
    "train_X, train_y, val_X, val_y = split_data(data, to_tensor, WINDOW_SIZE, Y_DIM, VALIDATION_RATIO)\n",
    "\n",
    "print('train_X, train_y :', train_X.shape, train_y.shape)\n",
    "print('  val_X,   val_y :', val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mEpoch: \u001b[36m  1/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.81s \u001b[35mloss:\u001b[94m 0.227675\u001b[35m val_loss:\u001b[94m 0.073213\u001b[0m\n",
      "Epoch 1: val_loss improved from inf to 0.07321, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  2/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.86s \u001b[35mloss:\u001b[94m 0.004271\u001b[35m val_loss:\u001b[94m 0.014231\u001b[0m\n",
      "Epoch 2: val_loss improved from 0.07321 to 0.01423, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  3/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.45s \u001b[35mloss:\u001b[94m 0.003218\u001b[35m val_loss:\u001b[94m 0.005791\u001b[0m\n",
      "Epoch 3: val_loss improved from 0.01423 to 0.00579, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  4/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.72s \u001b[35mloss:\u001b[94m 0.002798\u001b[35m val_loss:\u001b[94m 0.004166\u001b[0m\n",
      "Epoch 4: val_loss improved from 0.00579 to 0.00417, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  5/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.58s \u001b[35mloss:\u001b[94m 0.002245\u001b[35m val_loss:\u001b[94m 0.003145\u001b[0m\n",
      "Epoch 5: val_loss improved from 0.00417 to 0.00315, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  6/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.14s \u001b[35mloss:\u001b[94m 0.001833\u001b[35m val_loss:\u001b[94m 0.002218\u001b[0m\n",
      "Epoch 6: val_loss improved from 0.00315 to 0.00222, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  7/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.33s \u001b[35mloss:\u001b[94m 0.001512\u001b[35m val_loss:\u001b[94m 0.001589\u001b[0m\n",
      "Epoch 7: val_loss improved from 0.00222 to 0.00159, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  8/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.16s \u001b[35mloss:\u001b[94m 0.001323\u001b[35m val_loss:\u001b[94m 0.001305\u001b[0m\n",
      "Epoch 8: val_loss improved from 0.00159 to 0.00130, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m  9/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.62s \u001b[35mloss:\u001b[94m 0.001247\u001b[35m val_loss:\u001b[94m 0.002140\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 10/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.38s \u001b[35mloss:\u001b[94m 0.001169\u001b[35m val_loss:\u001b[94m 0.002809\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 11/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.57s \u001b[35mloss:\u001b[94m 0.001083\u001b[35m val_loss:\u001b[94m 0.002036\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 12/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.43s \u001b[35mloss:\u001b[94m 0.000998\u001b[35m val_loss:\u001b[94m 0.001267\u001b[0m\n",
      "Epoch 12: val_loss improved from 0.00130 to 0.00127, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 13/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.05s \u001b[35mloss:\u001b[94m 0.000928\u001b[35m val_loss:\u001b[94m 0.001390\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 14/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.22s \u001b[35mloss:\u001b[94m 0.000890\u001b[35m val_loss:\u001b[94m 0.000970\u001b[0m\n",
      "Epoch 14: val_loss improved from 0.00127 to 0.00097, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 15/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.33s \u001b[35mloss:\u001b[94m 0.000854\u001b[35m val_loss:\u001b[94m 0.000825\u001b[0m\n",
      "Epoch 15: val_loss improved from 0.00097 to 0.00083, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 16/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.78s \u001b[35mloss:\u001b[94m 0.000822\u001b[35m val_loss:\u001b[94m 0.001544\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 17/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.27s \u001b[35mloss:\u001b[94m 0.000839\u001b[35m val_loss:\u001b[94m 0.001013\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 18/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.35s \u001b[35mloss:\u001b[94m 0.000875\u001b[35m val_loss:\u001b[94m 0.001824\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 19/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.16s \u001b[35mloss:\u001b[94m 0.000796\u001b[35m val_loss:\u001b[94m 0.001438\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 20/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.48s \u001b[35mloss:\u001b[94m 0.000763\u001b[35m val_loss:\u001b[94m 0.000818\u001b[0m\n",
      "Epoch 20: val_loss improved from 0.00083 to 0.00082, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 21/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.43s \u001b[35mloss:\u001b[94m 0.000786\u001b[35m val_loss:\u001b[94m 0.000771\u001b[0m\n",
      "Epoch 21: val_loss improved from 0.00082 to 0.00077, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 22/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.22s \u001b[35mloss:\u001b[94m 0.000794\u001b[35m val_loss:\u001b[94m 0.000748\u001b[0m\n",
      "Epoch 22: val_loss improved from 0.00077 to 0.00075, saving file to /Users/kael/Codes/ml/DA-RNN/notebook/checkpoint_torch.hdf5\n",
      "\u001b[35mEpoch: \u001b[36m 23/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.20s \u001b[35mloss:\u001b[94m 0.000799\u001b[35m val_loss:\u001b[94m 0.001097\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 24/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.89s \u001b[35mloss:\u001b[94m 0.000806\u001b[35m val_loss:\u001b[94m 0.000832\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 25/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.68s \u001b[35mloss:\u001b[94m 0.000761\u001b[35m val_loss:\u001b[94m 0.001119\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 26/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.65s \u001b[35mloss:\u001b[94m 0.000795\u001b[35m val_loss:\u001b[94m 0.000973\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 27/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m53.53s \u001b[35mloss:\u001b[94m 0.000772\u001b[35m val_loss:\u001b[94m 0.001099\u001b[0m\n",
      "\u001b[35mEpoch: \u001b[36m 28/100 \u001b[35mTrain steps: \u001b[36m127 \u001b[35mVal steps: \u001b[36m32 \u001b[32m54.10s \u001b[35mloss:\u001b[94m 0.000787\u001b[35m val_loss:\u001b[94m 0.000791\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from da_rnn.torch import DARNN, DEVICE\n",
    "from poutyne import Model, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "darnn = DARNN(\n",
    "    n=train_X.shape[2] - 1,\n",
    "    T=WINDOW_SIZE,\n",
    "    m=ENCODER_HIDDEN_STATES,\n",
    "    p=DECODER_HIDDEN_STATES,\n",
    "    y_dim=Y_DIM,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    darnn,\n",
    "    'adam',\n",
    "    'mse',\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "save_to = dirname / 'checkpoint_torch.hdf5'\n",
    "\n",
    "history = model.fit(\n",
    "    train_X, train_y,\n",
    "    validation_data=(val_X, val_y),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=5),\n",
    "        ModelCheckpoint(\n",
    "            str(save_to.absolute()),\n",
    "            monitor='val_loss',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            keep_only_last_best=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def predict(model, X):\n",
    "    with torch.no_grad():\n",
    "        return model(X)\n",
    "    \n",
    "\n",
    "train_y_hat = predict(darnn, train_X)\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.plot(\n",
    "    scale.inverse_transform(train_y_hat.cpu().repeat(1,82).numpy())[:,-1],\n",
    "    'k',\n",
    "    scale.inverse_transform(train_y.repeat(1,82).numpy())[:,-1],\n",
    "    'r'\n",
    ")\n",
    "\n",
    "val_y_hat = predict(darnn, val_X)\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.plot(\n",
    "    scale.inverse_transform(val_y_hat.cpu().repeat(1,82).numpy())[:,-1],\n",
    "    'k',\n",
    "    scale.inverse_transform(val_y.repeat(1,82).numpy())[:,-1],\n",
    "    'r'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
